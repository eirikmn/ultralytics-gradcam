{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#plot a cv2 image\n",
    "import cv2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add modified YOLOv8 library (cloned from git: URL)\n",
    "\n",
    "\n",
    "from ultralytics import YOLO #make sure you do not have another library with the same name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-trained model\n",
    "model = YOLO(\"forams4-1280-augmentedraw-bigtest-200epochs-yolov8x.pt\")\n",
    "\n",
    "#load example image\n",
    "im0 = Image.open(\"sampleimg-0.jpg\")\n",
    "im1 = Image.open(\"sampleimg-1.jpg\")\n",
    "im2 = Image.open(\"sampleimg-2.jpg\")\n",
    "im3 = Image.open(\"sampleimg-3.jpg\")\n",
    "\n",
    "#run prediction with visualize = True to generate heatmap\n",
    "#results = model.predict(source=im3, save=False, visualize = True)  # save plotted images\n",
    "\n",
    "#The results are stored in /runs/detect/predict.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelreader(labpath=None):\n",
    "        labels = []\n",
    "        with open(labpath, 'r') as f:\n",
    "            for line in f:\n",
    "                #append each line to the labels as floats\n",
    "                labels.append(line.strip())\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            labels[i] = labels[i].split(' ')\n",
    "            for j in range(len(labels[i])):\n",
    "                labels[i][j] = float(labels[i][j])\n",
    "\n",
    "        #cast each element to float and store to tensor\n",
    "        labels = torch.tensor(labels)\n",
    "        return labels\n",
    "\n",
    "\n",
    "def plot_heatmap(image, bboxes = None, savename = None, plot=False):\n",
    "    \n",
    "    cam_img = image\n",
    "    \n",
    "    if bboxes is not None:\n",
    "        colors = [[0, 0, 255], [0, 255, 0], [255, 0, 0], [255,255,255]]\n",
    "        boxlabels = [\"sediment\", \"agglutinated\", \"calcareous\", \"planktic\"]\n",
    "        labheight = -10\n",
    "        labwidth = -7\n",
    "        imgsz = (image.shape[0],image.shape[1])\n",
    "        for i in range(bboxes.shape[0]):\n",
    "            box = bboxes[i,:]\n",
    "            cls = box[0]\n",
    "            cls = int(cls)\n",
    "            xc = float(box[1])\n",
    "            yc = float(box[2])\n",
    "            w = float(box[3])\n",
    "            h = float(box[4])\n",
    "            x1 = round((xc-0.5*w)*imgsz[0])\n",
    "            x2 = round((xc+0.5*w)*imgsz[0])\n",
    "            y1 = round((yc-0.5*h)*imgsz[1])\n",
    "            y2 = round((yc+0.5*h)*imgsz[1])\n",
    "            \n",
    "            cv2.rectangle(cam_img, (x1, y1), (x2, y2), colors[cls], 2)\n",
    "            cv2.putText(cam_img, boxlabels[cls], (x1+labwidth, y1+labheight),cv2.FONT_HERSHEY_SIMPLEX, 0.8, colors[cls], 2)\n",
    "    \n",
    "    if savename is not None:\n",
    "        cv2.imwrite(savename, cam_img)\n",
    "    if plot:\n",
    "        cv2.imshow(\"image\",cam_img)\n",
    "    \n",
    "    return cam_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigen CAM #\n",
    "\n",
    "#from #https://github.com/rigvedrs/YOLO-V8-CAM/blob/main/YOLO%20v8n%20EigenCAM.ipynb\n",
    "\n",
    "from yolo_cam.eigen_cam import EigenCAM\n",
    "from yolo_cam.utils.image import show_cam_on_image, scale_cam_image\n",
    "\n",
    "model = YOLO('forams4-1280-augmentedraw-bigtest-200epochs-yolov8x.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1280, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1280x1280 1 calcareous, 33 planktics, 3058.3ms\n",
      "Speed: 4.1ms preprocess, 3058.3ms inference, 0.6ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1280, 3)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "sampleid = 3\n",
    "samplename = \"sampleimg-\" + str(sampleid)\n",
    "\n",
    "img = cv2.imread(samplename + \".jpg\")\n",
    "labpath = samplename + \".txt\"\n",
    "savename = samplename + \"-eigencam.jpg\"\n",
    "\n",
    "#img = cv2.resize(img, (640, 640))\n",
    "#img = cv2.resize(img, (1280, 1280))\n",
    "rgb_img = img.copy()\n",
    "img = np.float32(img) / 255\n",
    "print(img.shape)\n",
    "#plt.imshow(img)\n",
    "#plt.show()\n",
    "\n",
    "target_layers =[model.model.model[-4]]\n",
    "\n",
    "cam = EigenCAM(model, target_layers,task='od')\n",
    "grayscale_cam = cam(rgb_img)[0, :, :]\n",
    "cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=False)\n",
    "#plt.imshow(cam_image)\n",
    "#plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "g_scale = np.stack([grayscale_cam] * 3, axis=2)\n",
    "#plt.imshow(g_scale)\n",
    "#cv2.imshow(cam_image)\n",
    "\n",
    "#im = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR)\n",
    "im = rgb_img\n",
    "Image.fromarray(np.hstack((im, cam_image)))\n",
    "\n",
    "print(cam_image.shape)\n",
    "\n",
    "#load labels into useable format\n",
    "bboxes = labelreader(labpath)\n",
    "\n",
    "eigenimg = plot_heatmap(cam_image, bboxes = bboxes, savename = savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block defines some useful functions\n",
    "\n",
    "# define a function that reads the labels from the label file\n",
    "def labelreader(labpath=None):\n",
    "        labels = []\n",
    "        with open(labpath, 'r') as f:\n",
    "            for line in f:\n",
    "                #append each line to the labels as floats\n",
    "                labels.append(line.strip())\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            labels[i] = labels[i].split(' ')\n",
    "            for j in range(len(labels[i])):\n",
    "                labels[i][j] = float(labels[i][j])\n",
    "\n",
    "        #cast each element to float and store to tensor\n",
    "        labels = torch.tensor(labels)\n",
    "        return labels\n",
    "\n",
    "\n",
    "#This function generates an image where the CAM heatmap has been overlayed onto the original image\n",
    "def make_heatmap(image, heatmap, transparancy = 0.3, plot=False):\n",
    "    heatmapp = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    \n",
    "    imgg = image.astype(np.uint8)\n",
    "    cam_img = transparancy * heatmapp + (1-transparancy) * imgg\n",
    "    cam_img = cam_img.astype(np.uint8)\n",
    "    \n",
    "    if plot:\n",
    "        cv2.imshow(\"image\",cam_img)\n",
    "    \n",
    "    return cam_img\n",
    "\n",
    "\n",
    "\n",
    "# This function plots the heatmap and the bounding boxes on the same image\n",
    "def plot_heatmap(image, heatmap, bboxes = None, transparancy = 0.3, savename = None):\n",
    "    \n",
    "    cam_img = make_heatmap(image, heatmap, transparancy, plot=False)\n",
    "    \n",
    "    if bboxes is not None:\n",
    "        colors = [[0, 0, 255], [0, 255, 0], [255, 0, 0], [255,255,255]]\n",
    "        boxlabels = [\"sediment\", \"agglutinated\", \"calcareous\", \"planktic\"]\n",
    "        labheight = -10\n",
    "        labwidth = -7\n",
    "        imgsz = (image.shape[0],image.shape[1])\n",
    "        for i in range(bboxes.shape[0]):\n",
    "            box = bboxes[i,:]\n",
    "            cls = box[0]\n",
    "            cls = int(cls)\n",
    "            xc = float(box[1])\n",
    "            yc = float(box[2])\n",
    "            w = float(box[3])\n",
    "            h = float(box[4])\n",
    "            x1 = round((xc-0.5*w)*imgsz[0])\n",
    "            x2 = round((xc+0.5*w)*imgsz[0])\n",
    "            y1 = round((yc-0.5*h)*imgsz[1])\n",
    "            y2 = round((yc+0.5*h)*imgsz[1])\n",
    "            \n",
    "            cv2.rectangle(cam_img, (x1, y1), (x2, y2), colors[cls], 2)\n",
    "            cv2.putText(cam_img, boxlabels[cls], (x1+labwidth, y1+labheight),cv2.FONT_HERSHEY_SIMPLEX, 0.8, colors[cls], 2)\n",
    "    \n",
    "    if savename is not None:\n",
    "        cv2.imwrite(savename, cam_img)\n",
    "    cv2.imshow(\"image\",cam_img)\n",
    "    \n",
    "    return cam_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets reload the image as a cv2 image\n",
    "image = cv2.imread(\"sampleimg-3.jpg\")\n",
    "\n",
    "#give the path to the label file of the sample image\n",
    "labpath = \"sampleimg-3.txt\"\n",
    "\n",
    "#load labels into useable format\n",
    "bboxes = labelreader(labpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import the heatmap from the \n",
    "\n",
    "run = 4 #run number for the prediction\n",
    "# 0: \"\"\n",
    "# 1: 2\n",
    "# 2: 3\n",
    "# 3: 4\n",
    "\n",
    "layer = 21 #which layer to use for the heatmap\n",
    "\n",
    "resultfolder = \"./runs/detect/\"+ \"predict\" + str(run) + \"/\"\n",
    "\n",
    "#load heatmap\n",
    "heatmap = np.load(resultfolder + str(layer) + \".npy\")\n",
    "\n",
    "\n",
    "#run the function\n",
    "savename = \"sampleimg\"+str(run)+\"-heatmap.jpg\"\n",
    "cam_img = plot_heatmap(image,heatmap, bboxes, transparancy = 0.3, savename = savename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOLO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39myolo_cam\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m show_cam_on_image, scale_cam_image\n\u001b[1;32m      9\u001b[0m \u001b[39m#load model\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model \u001b[39m=\u001b[39m YOLO(\u001b[39m'\u001b[39m\u001b[39mforams4-1280-augmentedraw-bigtest-200epochs-yolov8x.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39msampleimg-0.jpg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39m#rgb_img = img.copy()\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'YOLO' is not defined"
     ]
    }
   ],
   "source": [
    "# Eigen CAM #\n",
    "\n",
    "#from #https://github.com/rigvedrs/YOLO-V8-CAM/blob/main/YOLO%20v8n%20EigenCAM.ipynb\n",
    "\n",
    "from yolo_cam.eigen_cam import EigenCAM\n",
    "from yolo_cam.utils.image import show_cam_on_image, scale_cam_image\n",
    "\n",
    "\n",
    "#load model\n",
    "model = YOLO('forams4-1280-augmentedraw-bigtest-200epochs-yolov8x.pt')\n",
    "\n",
    "img = cv2.imread('sampleimg-0.jpg')\n",
    "#rgb_img = img.copy()\n",
    "rgb_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"img\",img)\n",
    "#plt.show()\n",
    "\n",
    "img = np.float32(img) / 255\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "#target_layers =[model.model.model[-4]]\n",
    "target_layers = [model.model.model[21]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 1280, 3)\n",
      "\n",
      "\n",
      " YOLO call \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " predict\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " type(self.predictor)\n",
      " \n",
      "<class 'ultralytics.yolo.v8.detect.predict.DetectionPredictor'>\n",
      "<class 'ultralytics.nn.autobackend.AutoBackend'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " basepredictor __call__ \n",
      "\n",
      "<class 'ultralytics.nn.autobackend.AutoBackend'>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " basepredictor stream_inference \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " batch#\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " batch reqgrad\n",
      "\n",
      "False\n",
      "\n",
      "\n",
      " autobackend forward \n",
      "\n",
      "\n",
      "b, ch, h, w \n",
      "\n",
      "1 3 1280 1280\n",
      "autobackend self.pt or self.nn_module \n",
      "\n",
      "<class 'ultralytics.nn.tasks.DetectionModel'>\n",
      "predict once\n",
      "<class 'ultralytics.nn.modules.conv.Conv'>\n",
      "<class 'ultralytics.nn.modules.conv.Conv'>\n",
      "<class 'ultralytics.nn.modules.block.C2f'>\n",
      "<class 'ultralytics.nn.modules.conv.Conv'>\n",
      "<class 'ultralytics.nn.modules.block.C2f'>\n",
      "<class 'ultralytics.nn.modules.conv.Conv'>\n",
      "<class 'ultralytics.nn.modules.block.C2f'>\n",
      "<class 'ultralytics.nn.modules.conv.Conv'>\n",
      "<class 'ultralytics.nn.modules.block.C2f'>\n",
      "<class 'ultralytics.nn.modules.block.SPPF'>\n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      "<class 'ultralytics.nn.modules.conv.Concat'>\n",
      "<class 'ultralytics.nn.modules.block.C2f'>\n",
      "<class 'torch.nn.modules.upsampling.Upsample'>\n",
      "<class 'ultralytics.nn.modules.conv.Concat'>\n",
      "<class 'ultralytics.nn.modules.block.C2f'>\n",
      "<class 'ultralytics.nn.modules.conv.Conv'>\n",
      "<class 'ultralytics.nn.modules.conv.Concat'>\n",
      "<class 'ultralytics.nn.modules.block.C2f'>\n",
      "<class 'ultralytics.nn.modules.conv.Conv'>\n",
      "<class 'ultralytics.nn.modules.conv.Concat'>\n",
      "<class 'ultralytics.nn.modules.block.C2f'>\n",
      "<class 'ultralytics.nn.modules.head.Detect'>\n",
      "3\n",
      "\n",
      "\n",
      " autobackend forward y \n",
      "\n",
      "\n",
      "2\n",
      "list or tuple\n",
      "2\n",
      "<class 'torch.Tensor'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1280x1280 34 Sediments, 9 planktics, 4451.6ms\n",
      "Speed: 8.5ms preprocess, 4451.6ms inference, 224.2ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " visualize, save, write \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The input image should np.float32 in the range [0, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m cam \u001b[39m=\u001b[39m EigenCAM(model, target_layers,task\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mod\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m grayscale_cam \u001b[39m=\u001b[39m cam(rgb_img)[\u001b[39m0\u001b[39m, :, :]\n\u001b[0;32m---> 10\u001b[0m cam_image \u001b[39m=\u001b[39m show_cam_on_image(rgb_img, grayscale_cam, use_rgb\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m     14\u001b[0m g_scale \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack([grayscale_cam] \u001b[39m*\u001b[39m \u001b[39m3\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/Dropbox/Postdoc2/Kurs/NORA summer school 2023/NORAprosjekt/yolo_cam/utils/image.py:54\u001b[0m, in \u001b[0;36mshow_cam_on_image\u001b[0;34m(img, mask, use_rgb, colormap, image_weight)\u001b[0m\n\u001b[1;32m     51\u001b[0m heatmap \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfloat32(heatmap) \u001b[39m/\u001b[39m \u001b[39m255\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmax(img) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m     55\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe input image should np.float32 in the range [0, 1]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m image_weight \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m image_weight \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m     58\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m     59\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimage_weight should be in the range [0, 1].\u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m            Got: \u001b[39m\u001b[39m{\u001b[39;00mimage_weight\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: The input image should np.float32 in the range [0, 1]"
     ]
    }
   ],
   "source": [
    "\n",
    "img = np.float32(img) / 255\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "#target_layers =[model.model.model[-4]]\n",
    "target_layers = [model.model.model[21]]\n",
    "\n",
    "cam = EigenCAM(model, target_layers,task='od')\n",
    "grayscale_cam = cam(rgb_img)[0, :, :]\n",
    "cam_image = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "g_scale = np.stack([grayscale_cam] * 3, axis=2)\n",
    "#plt.imshow(g_scale)\n",
    "\n",
    "im = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2BGR)\n",
    "Image.fromarray(np.hstack((im, cam_image)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
